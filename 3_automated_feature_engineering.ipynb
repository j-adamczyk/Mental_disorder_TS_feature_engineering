{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e9ffdc",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28556408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import tsfel\n",
    "import tsfresh\n",
    "\n",
    "from utils import Dataset, variance_thresholding, standardize, mcc, calculate_metrics, calculate_metrics_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed485f",
   "metadata": {},
   "source": [
    "# Automated feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de33c34",
   "metadata": {},
   "source": [
    "## Utilities and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cb6ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data_cleaning(data: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - assure format YYYY-MM-DD HH:MM:SS for \"timestamp\"\n",
    "    - drop redundant \"date\" column\n",
    "    - assure float32 format for \"activity\"\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    \n",
    "    for df in data:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "        df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that correspond to the \n",
    "    chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) & (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) | (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Makes sure that \"timestamp\" column has minute resolution with no missing values from start to end and replaces \n",
    "    all NaNs in \"activity\" column with mean average value.\n",
    "    \n",
    "    :param data: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :returns: cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for any rows that may be missing\n",
    "    df = df.resample(\"min\", on=\"timestamp\").mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def resample(df: pd.DataFrame, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating each segment with a mean.\n",
    "\n",
    "    :param df: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency string passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # make sure that data has minute resolution with no missing parts from start to end, with no missing values\n",
    "    df = fill_missing_activity(df)\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\").mean()\n",
    "\n",
    "    # recreate \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_clean_dataframes(dfs: List[pd.DataFrame], freq: str = \"H\") -> Dict[str, List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Cleans DataFrames, filling missing values and resampling with given frequency.\n",
    "    \n",
    "    Returns three lists of DataFrames:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of DataFrames to clean; each one has to have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding to data from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    full_dfs = [fill_missing_activity(df) for df in full_dfs]\n",
    "    full_dfs = [resample(df, freq=freq) for df in full_dfs]\n",
    "    \n",
    "    night_dfs = [get_day_part(df, part=\"night\") for df in full_dfs]\n",
    "    day_dfs = [get_day_part(df, part=\"day\") for df in full_dfs]\n",
    "\n",
    "    datasets = {\n",
    "        \"full_24h\": full_dfs,\n",
    "        \"night\": night_dfs,\n",
    "        \"day\": day_dfs\n",
    "    }\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_tsfresh_flat_format_df(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates DataFrame in a \"flat\" format for tsfresh from list of DataFrames. Each one is assumed to have \n",
    "    \"timestamp\" and \"activity\" columns.\n",
    "    \n",
    "    :param dfs: list of DataFrames; each one has to have \"timestamp\" and \"activity\" columns\n",
    "    :returns: DataFrame in tsfresh \"flat\" format\n",
    "    \"\"\"\n",
    "    dfs = deepcopy(dfs)  # create copy to avoid side effects\n",
    "    \n",
    "    flat_df = pd.DataFrame(columns=[\"id\", \"timestamp\", \"activity\"])\n",
    "\n",
    "    for idx, df in enumerate(dfs):\n",
    "        df[\"id\"] = idx\n",
    "        flat_df = flat_df.append(df)\n",
    "\n",
    "    flat_df = flat_df.reset_index(drop=True)\n",
    "        \n",
    "    return flat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3699e",
   "metadata": {},
   "source": [
    "## Parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ac2f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        random_state=0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=5000\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\",\n",
    "        cache_size=512\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        criterion=\"entropy\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"LR\": {\n",
    "        \"C\": [0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 25, 50, 100, 500, 1000],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"l1_ratio\": [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "                     0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"gamma\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b58635",
   "metadata": {},
   "source": [
    "## tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0fdb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", \"depresjon\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "529f187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = get_clean_dataframes(condition, freq=\"min\")\n",
    "control_parts_dfs = get_clean_dataframes(control, freq=\"min\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_dfs_list = condition_parts_dfs[part]\n",
    "    control_dfs_list = control_parts_dfs[part]\n",
    "    \n",
    "    dfs_list = condition_dfs_list + control_dfs_list\n",
    "    flat_df = get_tsfresh_flat_format_df(dfs_list)\n",
    "    \n",
    "    datasets[part] = flat_df\n",
    "\n",
    "\n",
    "y = np.concatenate((np.ones(len(condition)), np.zeros(len(control)))).astype(int)\n",
    "y = pd.Series(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce668c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    X = datasets[part]\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9299ee",
   "metadata": {},
   "source": [
    "## TSFEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002234d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
