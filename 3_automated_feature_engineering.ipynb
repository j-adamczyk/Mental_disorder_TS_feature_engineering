{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e9ffdc",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28556408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "import tsfel\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction.settings import ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from tsfresh.transformers import RelevantFeatureAugmenter, FeatureAugmenter, FeatureSelector\n",
    "\n",
    "from utils import Dataset, variance_thresholding, standardize, mcc, calculate_metrics, calculate_metrics_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for saving data\n",
    "PROCESSED_DATA_DIR = \"processed_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed485f",
   "metadata": {},
   "source": [
    "# Automated feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de33c34",
   "metadata": {},
   "source": [
    "## Utilities and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data_cleaning(data: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - assure format YYYY-MM-DD HH:MM:SS for \"timestamp\"\n",
    "    - drop redundant \"date\" column\n",
    "    - assure float32 format for \"activity\"\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    \n",
    "    for df in data:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "        df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that correspond to the \n",
    "    chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) & (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) | (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Makes sure that \"timestamp\" column has minute resolution with no missing values from start to end and replaces \n",
    "    all NaNs in \"activity\" column with mean average value.\n",
    "    \n",
    "    :param data: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :returns: cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for any rows that may be missing\n",
    "    df = df.resample(\"min\", on=\"timestamp\").mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def resample(df: pd.DataFrame, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating each segment with a mean.\n",
    "\n",
    "    :param df: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency string passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # make sure that data has minute resolution with no missing parts from start to end, with no missing values\n",
    "    df = fill_missing_activity(df)\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\").mean()\n",
    "\n",
    "    # recreate \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_clean_dataframes(dfs: List[pd.DataFrame], freq: str = \"H\") -> Dict[str, List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Cleans DataFrames, filling missing values and resampling with given frequency.\n",
    "    \n",
    "    Returns three lists of DataFrames:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of DataFrames to clean; each one has to have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding to data from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    full_dfs = [fill_missing_activity(df) for df in full_dfs]\n",
    "    full_dfs = [resample(df, freq=freq) for df in full_dfs]\n",
    "    \n",
    "    night_dfs = [get_day_part(df, part=\"night\") for df in full_dfs]\n",
    "    day_dfs = [get_day_part(df, part=\"day\") for df in full_dfs]\n",
    "\n",
    "    datasets = {\n",
    "        \"full_24h\": full_dfs,\n",
    "        \"night\": night_dfs,\n",
    "        \"day\": day_dfs\n",
    "    }\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def get_tsfresh_flat_format_df(dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates DataFrame in a \"flat\" format for tsfresh from list of DataFrames. Each one is assumed to have \n",
    "    \"timestamp\" and \"activity\" columns.\n",
    "    \n",
    "    :param dfs: list of DataFrames; each one has to have \"timestamp\" and \"activity\" columns\n",
    "    :returns: DataFrame in tsfresh \"flat\" format\n",
    "    \"\"\"\n",
    "    dfs = deepcopy(dfs)  # create copy to avoid side effects\n",
    "    \n",
    "    flat_df = pd.DataFrame(columns=[\"id\", \"timestamp\", \"activity\"])\n",
    "\n",
    "    for idx, df in enumerate(dfs):\n",
    "        df[\"id\"] = idx\n",
    "        flat_df = flat_df.append(df)\n",
    "\n",
    "    flat_df = flat_df.reset_index(drop=True)\n",
    "        \n",
    "    return flat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3699e",
   "metadata": {},
   "source": [
    "## Parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LR\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        random_state=0,\n",
    "        solver=\"saga\",\n",
    "        max_iter=5000\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        kernel=\"rbf\",\n",
    "        cache_size=512\n",
    "    ),\n",
    "    \"RF\": RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        criterion=\"entropy\"\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "param_grids = {\n",
    "    \"LR\": {\n",
    "        \"C\": [0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10, 25, 50, 100, 500, 1000],\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"l1_ratio\": [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "                     0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"gamma\": np.logspace(10e-3, 10e3, num=50),\n",
    "        \"class_weight\": [None, \"balanced\"]\n",
    "    },\n",
    "    \"RF\": {\n",
    "        \"class_weight\": [None, \"balanced\", \"balanced_subsample\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b58635",
   "metadata": {},
   "source": [
    "## tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061d193",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dab571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsfresh_features(dfs: List[pd.DataFrame], settings: Dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs feature extraction (only extraction, not selection) using tsfresh.\n",
    "    \n",
    "    :param dfs: list of DataFrames with time series, each with \"timestamp\" and \"activity\" columns\n",
    "    :param settings: tsfresh settings, one of: ComprehensiveFCParameters, EfficientFCParameters, MinimalFCParameters\n",
    "    :returns: DataFrame with extracted features, with one row per original DataFrame with time series (in the same order)\n",
    "    \"\"\"\n",
    "    ts = get_tsfresh_flat_format_df(dfs)\n",
    "    ids = ts[\"id\"].unique()\n",
    "    X = pd.DataFrame(index=ids)\n",
    "    \n",
    "    augmenter = FeatureAugmenter(\n",
    "        default_fc_parameters=settings,\n",
    "        column_id=\"id\",\n",
    "        column_sort=\"timestamp\",\n",
    "        column_value=\"activity\",\n",
    "        chunksize=1,\n",
    "        n_jobs=4\n",
    "    )\n",
    "    \n",
    "    augmenter.set_timeseries_container(ts)\n",
    "    X = augmenter.transform(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "class IncreasingFDRFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.selector: FeatureSelector = None\n",
    "        self.verbose: bool = verbose\n",
    "        self.final_alpha: float = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        final_alpha = None\n",
    "        for alpha in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5,\n",
    "                      0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1.0]:\n",
    "            self.selector = FeatureSelector(\n",
    "                fdr_level=alpha,\n",
    "                n_jobs=4,\n",
    "                chunksize=1\n",
    "            )\n",
    "            self.selector.fit(X_train, y_train)\n",
    "            if len(self.selector.relevant_features) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                return selector\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"FDR:\", self.final_alpha)\n",
    "        \n",
    "        raise ValueError(\"Failed to select any features\")\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.selector.transform(X)\n",
    "\n",
    "\n",
    "class TsfreshTopNFeatureSelector(BaseEstimator, TransformerMixin):   \n",
    "    def __init__(self, n: int = 10):\n",
    "        self.n: int = n\n",
    "        self.features: List[int] = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        \n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y)\n",
    "        \n",
    "        relevance_table = calculate_relevance_table(X, y)\n",
    "        relevance_table.sort_values(\"p_value\", inplace=True)\n",
    "        features = relevance_table.head(self.n)[\"feature\"]\n",
    "        self.features = list(features.values)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c1666",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a28c6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"psykose\"  # \"depresjon\" or \"psykose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0fdb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", dataset_str))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "529f187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = get_clean_dataframes(condition, freq=\"min\")\n",
    "control_parts_dfs = get_clean_dataframes(control, freq=\"min\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_dfs_list = condition_parts_dfs[part]\n",
    "    control_dfs_list = control_parts_dfs[part]\n",
    "    \n",
    "    dfs_list = condition_dfs_list + control_dfs_list\n",
    "    datasets[part] = dfs_list\n",
    "\n",
    "y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82fa99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 54/54 [06:23<00:00,  7.10s/it]\n"
     ]
    }
   ],
   "source": [
    "settings_dict = {\"minimal\": MinimalFCParameters(), \"efficient\": EfficientFCParameters()}\n",
    "\n",
    "for part, dfs in datasets.items():\n",
    "    for settings_name, settings in settings_dict.items():\n",
    "        X = extract_tsfresh_features(dfs, settings)\n",
    "        filename = f\"automatic_tsfresh_{dataset_str}_{settings_name}_{part}.csv\"\n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        X.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a118c7",
   "metadata": {},
   "source": [
    "### Minimal settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a75cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"depresjon\"  # \"depresjon\" or \"psykose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477be090",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    filename = f\"automatic_tsfresh_{dataset_str}_minimal_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    X = pd.read_csv(filepath, header=0).fillna(0).values\n",
    "    \n",
    "    y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb0764",
   "metadata": {},
   "source": [
    "### Efficient settings, increasing FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"psykose\"  # \"depresjon\" or \"psykose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    filename = f\"automatic_tsfresh_{dataset_str}_efficient_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    X = pd.read_csv(filepath, header=0).fillna(0).values\n",
    "    \n",
    "    y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "            \n",
    "            selector = IncreasingFDRFeatureSelector(verbose=True)\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train, X_test = selector.transform(X_train), selector.transform(X_test)\n",
    "            \n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7670a28d",
   "metadata": {},
   "source": [
    "### Efficient settings, top N features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6fa54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"psykose\"  # \"depresjon\" or \"psykose\"\n",
    "\n",
    "top_n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91732bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    filename = f\"automatic_tsfresh_{dataset_str}_efficient_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    X = pd.read_csv(filepath, header=0).fillna(0).values\n",
    "    \n",
    "    y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "\n",
    "            selector = TsfreshTopNFeatureSelector(n=top_n)\n",
    "            selector.fit(X_train, y_train)\n",
    "            X_train, X_test = selector.transform(X_train), selector.transform(X_test)\n",
    "            \n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9299ee",
   "metadata": {},
   "source": [
    "## TSFEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9593be4",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tsfel_features(dfs: List[pd.DataFrame]) ->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ede8d3",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1002234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"depresjon\"  # \"depresjon\" or \"psykose\"\n",
    "\n",
    "config = tsfel.get_features_by_domain(domain=None)  # domain: \"statistical\", \"spectral\", \"temporal\", None (all 3)\n",
    "sampling_rate = 1 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", dataset_str))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a182dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = get_clean_dataframes(condition, freq=\"min\")\n",
    "control_parts_dfs = get_clean_dataframes(control, freq=\"min\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_dfs_list = condition_parts_dfs[part]\n",
    "    control_dfs_list = control_parts_dfs[part]\n",
    "    \n",
    "    dfs_list = condition_dfs_list + control_dfs_list\n",
    "    datasets[part] = dfs_list\n",
    "\n",
    "y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b39425",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\"statistical\": \"statistical\", \"spectral\": \"spectral\", \"temporal\": \"temporal\", \"all\": None}\n",
    "\n",
    "for part, dfs in datasets.items():\n",
    "    for settings_name, settings in settings_dict.items():\n",
    "        X = extract_tsfresh_features(dfs, settings)\n",
    "        filename = f\"automatic_tsfresh_{dataset_str}_{settings_name}_{part}.csv\"\n",
    "        filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "        X.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2196141a",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9782b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_str = \"depresjon\"  # \"depresjon\" or \"psykose\"\n",
    "\n",
    "config = tsfel.get_features_by_domain(domain=None)  # domain: \"statistical\", \"spectral\", \"temporal\", None (all 3)\n",
    "sampling_rate = 1 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5f81123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART: full_24h\n",
      "  LR\n",
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 0% Complete\n",
       "              <p/>            \n",
       "              <progress\n",
       "                  value='0'\n",
       "                  max='44',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  0\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\tsfel\\feature_extraction\\calc_features.py\", line 185, in calc_features\n    feat_val = calc_window_features(dict_features, wind_sig, fs, features_path=features_path, header_names=names)\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\tsfel\\feature_extraction\\calc_features.py\", line 462, in calc_window_features\n    eval_result = eval(execf, locals())\n  File \"<string>\", line 1, in <module>\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\tsfel\\feature_extraction\\features.py\", line 930, in max_power_spectrum\n    return float(max(scipy.signal.welch(signal / np.std(signal), int(fs), nperseg=len(signal))[1]))\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\scipy\\signal\\spectral.py\", line 448, in welch\n    freqs, Pxx = csd(x, x, fs=fs, window=window, nperseg=nperseg,\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\scipy\\signal\\spectral.py\", line 582, in csd\n    freqs, _, Pxy = _spectral_helper(x, y, fs, window, nperseg, noverlap, nfft,\n  File \"C:\\Users\\jakub\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\scipy\\signal\\spectral.py\", line 1831, in _spectral_helper\n    freqs = sp_fft.rfftfreq(nfft, 1/fs)\nZeroDivisionError: division by zero\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3772/1534355339.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariance_thresholding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             X_train = tsfel.time_series_features_extractor(\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mdict_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0msignal_windows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\site-packages\\tsfel\\feature_extraction\\calc_features.py\u001b[0m in \u001b[0;36mtime_series_features_extractor\u001b[1;34m(dict_features, signal_windows, fs, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 features = pool.imap(partial(calc_features, dict_features=dict_features, fs=fs,\n\u001b[0;32m    296\u001b[0m                                              features_path=features_path, header_names=names), signal_windows)\n\u001b[1;32m--> 297\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                         \u001b[0mdisplay_progress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignal_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Mental_discorder_TS_feature_engineering\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    print(f\"PART: {part}\")\n",
    "    \n",
    "    filename = f\"automatic_{dataset_str}_efficient_{part}.csv\"\n",
    "    filepath = os.path.join(PROCESSED_DATA_DIR, filename)\n",
    "    X = pd.read_csv(filepath, header=0).fillna(0).values\n",
    "    \n",
    "    y = pd.read_csv(os.path.join(PROCESSED_DATA_DIR, f\"{dataset_str}_y.csv\"), header=None, dtype=int)\n",
    "    y = y.values.ravel()\n",
    "\n",
    "    for clf_type in [\"LR\", \"SVM\", \"RF\"]:\n",
    "        print(f\"  {clf_type}\")\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        \n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in folds.split(X, y):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            X_train, X_test = variance_thresholding(X_train, X_test, threshold=0.05)\n",
    "\n",
    "            X_train = tsfel.time_series_features_extractor(\n",
    "                dict_features=config,\n",
    "                signal_windows=X_train,\n",
    "                fs=sampling_rate,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            X_test = tsfel.time_series_features_extractor(\n",
    "                dict_features=config,\n",
    "                signal_windows=X_test,\n",
    "                fs=sampling_rate,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            correlated_features = tsfel.correlated_features(X_train)\n",
    "            X_train.drop(correlated_features, axis=1, inplace=True)\n",
    "            X_test.drop(correlated_features, axis=1, inplace=True)\n",
    "            \n",
    "            X_train, X_test = standardize(X_train, X_test)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=classifiers[clf_type], \n",
    "                param_grid=param_grids[clf_type], \n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                refit=True,\n",
    "                cv=LeaveOneOut()\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            clf = grid_search.best_estimator_\n",
    "            \n",
    "            metrics = calculate_metrics(clf, X_test, y_test)\n",
    "            print(metrics)\n",
    "            test_scores.append(metrics)\n",
    "        \n",
    "        final_scores = calculate_metrics_statistics(test_scores)\n",
    "        \n",
    "        for metric, (mean, stddev) in final_scores.items():\n",
    "            print(f\"    {metric}: {mean:.4f} +- {stddev:.4f}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c9948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
