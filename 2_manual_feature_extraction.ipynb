{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320837f7",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18e18bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from utils import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef0d95",
   "metadata": {},
   "source": [
    "# Manual feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9515d10",
   "metadata": {},
   "source": [
    "## Utilities and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "657c3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data_cleaning(data: List[pd.DataFrame]) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Assumes DataFrames with \"timestamp\", \"date\" and \"activity\" columns.\n",
    "    \n",
    "    Performs cleaning operations:\n",
    "    - assure format YYYY-MM-DD HH:MM:SS for \"timestamp\"\n",
    "    - drop redundant \"date\" column\n",
    "    - assure float32 format for \"activity\"\n",
    "    \n",
    "    :param data: list of DataFrames\n",
    "    :returns: list of cleaned DataFrames\n",
    "    \"\"\"\n",
    "    data = [df.copy() for df in data]  # create copy to avoid side effects\n",
    "    \n",
    "    for df in data:\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df.drop(\"date\", axis=1, inplace=True)\n",
    "        df[\"activity\"] = df[\"activity\"].astype(np.float32)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def get_day_part(df: pd.DataFrame, part: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For given DataFrame with \"timestamp\" column returns only those rows that correspond to the \n",
    "    chosen part of day.\n",
    "    \n",
    "    Parts are \"day\" and \"night\", defined as:\n",
    "    - \"day\": [8:00, 21:00)\n",
    "    - \"night\": [21:00, 8:00)\n",
    "    \n",
    "    :param df: DataFrame to select rows from\n",
    "    :param part: part of day, either \"day\" or \"night\"\n",
    "    :returns: DataFrame, subset of rows of df\n",
    "    \"\"\"\n",
    "    if part == \"day\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 8) & (df[\"timestamp\"].dt.hour < 21)]\n",
    "    elif part == \"night\":\n",
    "        df = df.loc[(df[\"timestamp\"].dt.hour >= 21) | (df[\"timestamp\"].dt.hour < 8)]\n",
    "    else:\n",
    "        raise ValueError(f'Part should be \"day\" or \"night\", got \"{part}\"')\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_activity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Makes sure that \"timestamp\" column has minute resolution with no missing values from start to end and replaces \n",
    "    all NaNs in \"activity\" column with mean average value.\n",
    "    \n",
    "    :param data: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    :returns: cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # resample to the basic frequency, i.e. minute; this will create NaNs for any rows that may be missing\n",
    "    df = df.resample(\"min\", on=\"timestamp\").mean()\n",
    "    \n",
    "    # recreate index and \"timestamp\" column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # fill any NaNs with mean activity value\n",
    "    df[\"activity\"] = df[\"activity\"].fillna(df[\"activity\"].mean())\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def total_power(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates total power for given signal. Estimates total power density (i.e. power spectrum) using \n",
    "    Welch method and then sums it (integrates discrete signal).\n",
    "    \n",
    "    :param df: DataFrame with \"activity\" column\n",
    "    :returns: total power\n",
    "    \"\"\"\n",
    "    x = df[\"activity\"].values\n",
    "    power_spectrum = scipy.signal.welch(x, nperseg=min(len(x), 256))[1]\n",
    "    return pd.Series(power_spectrum.sum())\n",
    "\n",
    "\n",
    "def resample_in_domain(df: pd.DataFrame, domain: str, freq: str = \"H\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resamples time series DataFrame with given frequency, aggregating with a window function.\n",
    "    Result is either in time or frequency domain, depending on \"domain\" argument value.\n",
    "    \n",
    "    Assumes DataFrame with \"timestamp\", \"date\" and \"activity\" columns. \n",
    "    \n",
    "    Options for \"domain\":\n",
    "    - \"time\": aggregates each period with simple mean (average)\n",
    "    - \"frequency\": aggregates each period calculating total power\n",
    "    \n",
    "    :param df: DataFrame with columns \"datetime\" and \"activity\"\n",
    "    :param domain: \"time\" or \"frequency\"\n",
    "    :param freq: resampling frequency string passed to Pandas resample() function\n",
    "    :returns: DataFrame with \"timestamp\" and \"activity\" columns\n",
    "    \"\"\"\n",
    "    df = df.copy()  # create copy to avoid side effects\n",
    "    \n",
    "    # make sure that data has minute resolution with no missing parts from start to end, with no missing values\n",
    "    df = fill_missing_activity(df)\n",
    "    \n",
    "    # group with given frequency\n",
    "    df = df.resample(freq, on=\"timestamp\")\n",
    "    \n",
    "    # aggregate in the proper domain\n",
    "    if domain == \"time\":\n",
    "        df = df.mean()\n",
    "        df = df.reset_index()\n",
    "    elif domain == \"frequency\":\n",
    "        df = df.agg(total_power)\n",
    "        \n",
    "        # clear index, as timestamp index is meaningless in frequency domain\n",
    "        df = df.reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError(f'Domain should be \"time\" or \"frequency\", got \"{domain}\"')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def spectral_flatness(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculates spectral flatness of a signal, i.e. a geometric mean of the power spectrum divided by \n",
    "    the arithmetic mean of the power spectrum.\n",
    "    \n",
    "    :param x: DataFrame with \"activity\" column\n",
    "    :returns: spectral flatness value\n",
    "    \"\"\"\n",
    "    x = df[\"activity\"].values\n",
    "    power_spectrum = scipy.signal.welch(x, nperseg=min(len(x), 256))[1]\n",
    "    return gmean(power_spectrum) / power_spectrum.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c465a53",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "16826d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_features(df_raw: pd.DataFrame, df_resampled: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in time domain.\n",
    "    \n",
    "    :param df_raw: DataFrame with \"timestamp\" and \"activity\" columns, with raw signal values\n",
    "    :param df_resampled: DataFrame resampled in time domain with another frequency\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = df_resampled[\"activity\"].values\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"stddev\": np.std(X, ddof=1),  # ddof=1 applies Bessel correction, i.e. division by (N-1) instead of N\n",
    "        \"variance\": np.var(X),\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9589aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frequency_features(df_raw: pd.DataFrame, df_resampled: pd.DataFrame, df_frequency: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts features from activity signal in frequency domain (precisely, in power domain, since it's assumed \n",
    "    that df_frequency has been aggregated with total power using PSD).\n",
    "    \n",
    "    :param df_raw: DataFrame with \"timestamp\" and \"activity\" columns, with raw signal values\n",
    "    :param df_resampled: DataFrame resampled in time domain with another frequency\n",
    "    :param df_frequency: DataFrame in frequency domain\n",
    "    :returns: DataFrame with a single row representing features\n",
    "    \"\"\"\n",
    "    X = df_frequency.values.ravel()\n",
    "    \n",
    "    features = {\n",
    "        \"minimum\": np.min(X),\n",
    "        \"maximum\": np.max(X),\n",
    "        \"mean\": np.mean(X),\n",
    "        \"median\": np.median(X),\n",
    "        \"stddev\": np.std(X, ddof=1),  # ddof=1 applies Bessel correction, i.e. division by (N-1) instead of N\n",
    "        \"variance\": np.var(X),\n",
    "        \"kurtosis\": sp.stats.kurtosis(X),\n",
    "        \"skewness\": sp.stats.skew(X),\n",
    "        \"coeff_of_var\": sp.stats.variation(X),\n",
    "        \"iqr\": sp.stats.iqr(X),\n",
    "        \"trimmed_mean\": sp.stats.trim_mean(X, proportiontocut=0.1),\n",
    "        \"entropy\": sp.stats.entropy(X, base=2),\n",
    "        \"spectral_flatness\": spectral_flatness(df_resampled)\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "94400e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_dataframes(dfs: List[pd.DataFrame], freq: str = \"H\") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Calculates time and frequency features for given DataFrames. Uses given frequency for resampling.\n",
    "    \n",
    "    Calculates features separately for:\n",
    "    - full 24hs\n",
    "    - days: [8:00, 21:00)\n",
    "    - nights: [21:00, 8:00)\n",
    "    \n",
    "    :param dfs: list of DataFrames to extract features from; each one has to have \"timestamp\" and \"activity\" columns\n",
    "    :param freq: resampling frequency\n",
    "    :returns: dictionary with keys \"full_24h\", \"day\" and \"night\", corresponding to features from given parts of day\n",
    "    \"\"\"\n",
    "    full_dfs = basic_data_cleaning(dfs)\n",
    "    night_dfs = [get_day_part(df, part=\"night\") for df in full_dfs]\n",
    "    day_dfs = [get_day_part(df, part=\"day\") for df in full_dfs]\n",
    "\n",
    "    day_part_dfs = {\"full_24h\": full_dfs, \"night\": night_dfs, \"day\": day_dfs}\n",
    "    datasets = {}\n",
    "\n",
    "    for part, list_of_dfs in day_part_dfs.items():\n",
    "        full_features = []\n",
    "        for df in list_of_dfs:\n",
    "            df_resampled = resample_in_domain(df, domain=\"time\", freq=freq)\n",
    "            df_frequency = resample_in_domain(df, domain=\"frequency\", freq=freq)\n",
    "\n",
    "            time_features = extract_time_features(df, df_resampled)\n",
    "            freq_features = extract_frequency_features(df, df_resampled, df_frequency)\n",
    "\n",
    "            features_merged = pd.merge(\n",
    "                time_features,\n",
    "                freq_features,\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "                suffixes=[\"_time\", \"_freq\"]\n",
    "            )\n",
    "            full_features.append(features_merged)\n",
    "\n",
    "        datasets[part] = pd.concat(full_features)\n",
    "        datasets[part].reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6d128",
   "metadata": {},
   "source": [
    "# Depresjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "278e4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", \"depresjon\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "eb28b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_df = condition_parts_dfs[\"full_24h\"]\n",
    "    control_df = control_parts_dfs[\"full_24h\"]\n",
    "    \n",
    "    entire_df = condition_df.append(control_df, ignore_index=True)\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "13e1b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"processed_data\"\n",
    "\n",
    "for part, df in datasets.items():\n",
    "    filename = f\"depresjon_{part}.csv\"\n",
    "    filepath = os.path.join(target_dir, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10ba1f",
   "metadata": {},
   "source": [
    "# Psykose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2e62ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(dirpath=os.path.join(\"data\", \"psykose\"))\n",
    "condition = dataset.condition\n",
    "control = dataset.control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "17a6d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_parts_dfs = extract_features_for_dataframes(condition, freq=\"H\")\n",
    "control_parts_dfs = extract_features_for_dataframes(control, freq=\"H\")\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for part in [\"full_24h\", \"night\", \"day\"]:\n",
    "    condition_df = condition_parts_dfs[\"full_24h\"]\n",
    "    control_df = control_parts_dfs[\"full_24h\"]\n",
    "    \n",
    "    entire_df = condition_df.append(control_df, ignore_index=True)\n",
    "    datasets[part] = entire_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c0cc4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"processed_data\"\n",
    "\n",
    "for part, df in datasets.items():\n",
    "    filename = f\"psykose_{part}.csv\"\n",
    "    filepath = os.path.join(target_dir, filename)\n",
    "    df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103f4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
